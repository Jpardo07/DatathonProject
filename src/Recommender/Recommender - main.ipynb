{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 22:39:27.272719: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-13 22:39:27.272736: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToDF = \"../../Inputs/Creados - Proyecto/\"\n",
    "fileToDF = \"dfVentasDefinitivo.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{pathToDF}{fileToDF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sólo ejecutar una vez, elimina primera columna si la exportación de dicho CSV no se realizó con el parámetro \"index=False\"\n",
    "df.drop(columns=df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depuración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"name\"] = df[\"name\"].apply(lambda x: re.sub(\"\\d+\\s*\\S*\\w+\\s*\\S*\\w\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"customer_id\", \"name\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 22:41:23.141929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-13 22:41:23.141961: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-13 22:41:23.141977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c19b3611085a): /proc/driver/nvidia/version does not exist\n",
      "2022-04-13 22:41:23.150703: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/DatathonProject/src/Recommender/Recommender - main.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f616666656374696f6e6174655f77696c627572227d/workspaces/DatathonProject/src/Recommender/Recommender%20-%20main.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m ratings \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(\u001b[39mdict\u001b[39m(df2))\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f616666656374696f6e6174655f77696c627572227d/workspaces/DatathonProject/src/Recommender/Recommender%20-%20main.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m movies \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices(\u001b[39mdict\u001b[39;49m(df2[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n",
      "File \u001b[0;32m/workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:793\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=714'>715</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=715'>716</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=716'>717</a>\u001b[0m   \u001b[39m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=717'>718</a>\u001b[0m \n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=718'>719</a>\u001b[0m \u001b[39m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=790'>791</a>\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=791'>792</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=792'>793</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4479\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=4476'>4477</a>\u001b[0m element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mnormalize_element(element)\n\u001b[1;32m   <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=4477'>4478</a>\u001b[0m batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m-> <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=4478'>4479</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mto_batched_tensor_list(batched_spec, element)\n\u001b[1;32m   <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=4479'>4480</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors:\n\u001b[1;32m   <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=4480'>4481</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid `element`. `element` should not be empty.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:363\u001b[0m, in \u001b[0;36mto_batched_tensor_list\u001b[0;34m(element_spec, element)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=342'>343</a>\u001b[0m \u001b[39m\"\"\"Returns a tensor list representation of the element.\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=343'>344</a>\u001b[0m \n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=344'>345</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=357'>358</a>\u001b[0m \u001b[39m    in any of their substructures.\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=358'>359</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=360'>361</a>\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=361'>362</a>\u001b[0m \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[0;32m--> <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=362'>363</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _to_tensor_list_helper(\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=363'>364</a>\u001b[0m     \u001b[39mlambda\u001b[39;49;00m state, spec, component: state \u001b[39m+\u001b[39;49m spec\u001b[39m.\u001b[39;49m_to_batched_tensor_list(\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=364'>365</a>\u001b[0m         component), element_spec, element)\n",
      "File \u001b[0;32m/workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:338\u001b[0m, in \u001b[0;36m_to_tensor_list_helper\u001b[0;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=334'>335</a>\u001b[0m   spec, component \u001b[39m=\u001b[39m value\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=335'>336</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m encode_fn(state, spec, component)\n\u001b[0;32m--> <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=337'>338</a>\u001b[0m \u001b[39mreturn\u001b[39;00m functools\u001b[39m.\u001b[39;49mreduce(\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=338'>339</a>\u001b[0m     reduce_fn, \u001b[39mzip\u001b[39;49m(nest\u001b[39m.\u001b[39;49mflatten(element_spec), nest\u001b[39m.\u001b[39;49mflatten(element)), [])\n",
      "File \u001b[0;32m/workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:336\u001b[0m, in \u001b[0;36m_to_tensor_list_helper.<locals>.reduce_fn\u001b[0;34m(state, value)\u001b[0m\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=333'>334</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce_fn\u001b[39m(state, value):\n\u001b[1;32m    <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=334'>335</a>\u001b[0m   spec, component \u001b[39m=\u001b[39m value\n\u001b[0;32m--> <a href='file:///workspaces/DatathonProject/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py?line=335'>336</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m encode_fn(state, spec, component)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ratings = tf.data.Dataset.from_tensor_slices(dict(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ratings.take(3):\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"customer_id\": x[\"customer_id\"],\n",
    "    \"name\": x[\"name\"]\n",
    "})\n",
    "movies = ratings.map(lambda x: x[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"customer_id\"]))\n",
    "\n",
    "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      movie_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.movie_model = movie_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(features[\"customer_id\"])\n",
    "    movie_embeddings = self.movie_model(features[\"name\"])\n",
    "\n",
    "    return self.task(user_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user and movie models.\n",
    "user_model = tf.keras.Sequential([\n",
    "    user_ids_vocabulary,\n",
    "    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "movie_model = tf.keras.Sequential([\n",
    "    movie_titles_vocabulary,\n",
    "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), 64)\n",
    "])\n",
    "\n",
    "# Define your objectives.\n",
    "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "    movies.batch(128).map(movie_model)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(user_model, movie_model, task)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Train for 3 epochs.\n",
    "model.fit(ratings.batch(4096), epochs=3)\n",
    "\n",
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "    movies.batch(100).map(lambda title: (title, model.movie_model(title))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some recommendations.\n",
    "_, titles = index(np.array([\"42\"]))\n",
    "print(f\"Top 3 recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('FirstRecommenderModel.tf')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf572a60f2270a32a2287ee5441c31c3f27de4f092d16eee7937505d14960a51"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
